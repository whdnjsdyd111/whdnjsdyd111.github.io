---
slug: RLRR
title: "Low-Rank Rescaled Vision Transformer Fine-Tuning: A Residual Design Approach"
tags: [RLRR, LoRA, Vision, Residual-based Low-Rank Rescaling, Residual, Rescaling, SVD]
---

논문 및 이미지 출처 : <https://openaccess.thecvf.com/content/CVPR2024/papers/Dong_Low-Rank_Rescaled_Vision_Transformer_Fine-Tuning_A_Residual_Design_Approach_CVPR_2024_paper.pdf>

# Abstract

### 초록 (Abstract)
Pre-trained Vision Transformers의 Parameter-efficient fine-tuning은 대부분의 pre-trained 파라미터를 고정(frozen)하면서, 최소한의 새로운 적응 파라미터를 학습하여 모델을 downstream task에 맞게 능숙하게 조정하는 것을 목표로 한다. Pre-trained 모델의 일반화 가능한 표현 능력을 유지하면서, task-specific한 특징을 획득하는 것 사이에서 균형을 맞추는 것이 주요 과제이다. 현재까지 이 미묘한 균형을 지도하는 데 초점을 맞춘 연구는 부족한 실정이다. 본 연구에서는 pre-trained 파라미터 행렬의 Singular Value Decomposition (SVD) 관점에서 이 문제를 접근하여, 기존 방법의 튜닝 다이내믹스에 대한 통찰을 제공한다. 이러한 이해를 바탕으로, Residual-based Low-Rank Rescaling (RLRR) fine-tuning 전략을 제안한다. 이 전략은 파라미터 튜닝의 유연성을 높이는 동시에 residual 디자인을 통해 새로운 파라미터가 pre-trained 모델에서 과도하게 벗어나지 않도록 보장한다. 다양한 downstream 이미지 분류 작업에 대한 광범위한 실험은, 새로운 파라미터의 양을 최소화하면서도 우리 방법이 경쟁력 있는 성능을 달성함을 보여준다. 우리는 이 연구가 기존 방법들을 해석하는 데 통합된 관점을 제공하고, 앞서 언급한 중요한 trade-off를 효과적으로 고려하는 새로운 접근 방식을 개발할 동기를 제공한다고 믿는다. 본 연구의 코드는 https://github.com/zstarN70/RLRR.git 에서 확인할 수 있다.

### 도입 (Introduction)
대규모 pre-trained 모델이 보여준 놀라운 능력에 대응하여, 컴퓨터 비전 및 자연어 처리 분야에서의 패러다임은 task-specific 모델을 훈련하는 것에서, pre-trained 모델을 fine-tuning하는 방향으로 변화하고 있다 [5, 19]. 이 과정에서, Parameter-Efficient Fine-Tuning (PEFT)은 대부분의 pre-trained 파라미터를 고정(frozen)한 채, 최소한의 새로운 적응 파라미터를 학습하여 모델을 downstream task에 맞게 능숙하게 조정하는 것을 목표로 하는 활발한 연구 영역으로 부상하고 있다.

PEFT의 핵심 과제는 pre-trained 모델의 generalization capacity를 훼손하지 않으면서 downstream task에 효율적으로 적응하는 것이다. 기존 연구 [8, 9, 12, 17]는 주로 PEFT의 효율적 적응 측면에 중점을 두고, pre-trained 모델 파라미터를 조정하는 다양한 전략을 고안해왔다. 그러나, pre-trained 모델의 capacity를 유지하면서 효과적인 task 적응을 가능하게 하는 균형을 맞추는 중요한 과제에 대해서는 상대적으로 적은 주목을 받아왔다. 우리는 pre-trained 모델이 본질적으로 강력한 generalization 능력을 가지고 있으며, 기존의 low-rank 전략 [4, 9, 13, 17]이 full fine-tuning을 초과하는 현상이 파라미터 행렬 튜닝 과정에서 상당한 redundancy가 존재함을 입증한다고 믿는다. 본 연구의 목표는 이 중요한 균형을 더 잘 이해하고, 이를 탐색하기 위해 한 발 더 나아가는 것이다.

우리는 각 pre-trained 파라미터 행렬을 Singular Value Decomposition (SVD)의 관점에서 분석하여, raw 행렬을 일련의 항으로 분해한다. 각 항은 left-singular column vector, right-singular row vector, 그리고 해당 singular value의 곱으로 이루어진다. 우리는 이러한 프레임워크를 통해 adaptation-based methods [8], LoRA [9], prompt-tuning [12], scaling and shifting [17]와 같은 주요 PEFT 전략들을 검토한다. 이 관점은 이러한 방법들이 downstream task에 대해 파라미터를 어떻게 튜닝하고 있는지, 그리고 그 튜닝의 정도를 이해하는 데 도움을 준다.

이 분석을 바탕으로, 우리는 residual 디자인을 포함한 low-rank rescaled fine-tuning 전략을 제안한다. 이 fine-tuning은 frozen 행렬과 low-rank 기반의 rescaling 및 shifting의 결합으로 구성되며, 행렬 튜닝에서 유연성을 높인다. residual 항의 포함은 튜닝된 파라미터가 pre-trained 모델에서 과도하게 벗어나지 않도록 하는 데 중요한 역할을 한다.

다양한 downstream 이미지 분류 작업에 대한 광범위한 실험은, 우리 방법이 기존 전략과 비교해 경쟁력 있는 성능을 달성하면서도 새로운 파라미터의 양을 최소화함을 보여준다. 본 연구의 기여는 다음과 같이 요약될 수 있다:
- **통합된 분석 프레임워크**: 우리는 SVD를 기반으로 pre-trained 파라미터 행렬을 분석하는 통합된 프레임워크를 도입하여, 주요 PEFT 전략들에 대한 포괄적인 이해를 제공한다.
- **Trade-off 탐색**: 기존 연구에서 간과된 부분을 보완하여, 우리는 PEFT에서 pre-trained 모델의 generalization capacity를 유지하면서 효율적으로 적응하는 균형을 탐색하는 데 중요한 진전을 이루었다.
- **제안된 방법**: 우리는 Residual Design을 포함한 새로운 Low-Rank Rescaled Fine-Tuning 전략을 제안한다. 이 방법은 frozen 행렬과 low-rank 기반의 rescaling 및 shifting의 결합으로 fine-tuning을 공식화하여, 행렬 튜닝에서 유연성을 높인다.
- **포괄적인 실험**: 다양한 downstream 이미지 분류 작업에서 광범위한 실험을 통해, 우리 방법이 새로운 파라미터를 최소화하면서도 경쟁력 있는 성능을 달성함을 보여준다.

### 2. 관련 연구
#### 2.1. 사전 학습과 전이 학습
다양한 연구 [11, 22, 29, 33]를 통해 전이 학습(Transfer Learning)은 다양한 도메인, 모달리티, 특정 작업 요구사항에 걸쳐 높은 적응성을 입증했다. 전이 학습은 대규모 데이터셋에서 사전 학습(pre-training)을 수행하고, 획득한 파라미터를 후속 작업의 초기화로 활용함으로써 성능과 수렴 속도를 크게 향상시켰다. 이러한 대규모 데이터셋은 사전 학습된 모델이 후속 작업에서 성능과 수렴 속도를 높이는 데 중요한 역할을 하며, 학습 효율성을 강화하는 강력한 일반화 능력을 부여한다. 또한, 자가 지도 사전 학습(self-supervised pre-training) [2, 7]은 수동 데이터 라벨링과 관련된 비용, 시간, 품질 문제를 완화하는 추가적인 이점을 제공한다.

컴퓨터 비전 분야에서는 초기 연구들이 ImageNet-1K 데이터셋 [3]을 활용한 사전 학습을 선호하여 후속 작업에서 더 빠른 수렴과 향상된 성능을 달성했다. 그러나 Vision Transformer (ViT) [5] 및 Swin Transformer [19]와 같은 대규모 모델이 등장함에 따라, 연구자들은 ImageNet-21K [3]와 JFT-300M [25]과 같은 더 광범위한 데이터셋을 활용한 사전 학습으로 전환하여, 더 나은 학습 효율성과 강건함을 추구하게 되었다. 그럼에도 불구하고, 대규모 모델의 도입은 후속 작업을 위해 미세 조정(fine-tuning)하는 과정에서 상당한 계산 자원 요구라는 과제를 안고 있다. 따라서, 연구자들은 효율적인 미세 조정을 달성하기 위한 방법들을 탐구하기 시작했다.

#### 2.2. 파라미터 효율적 미세 조정 (PEFT)
전체 네트워크를 후속 작업에 맞춰 미세 조정하는 과정에서 발생하는 파라미터 폭증의 문제를 완화하기 위해, 파라미터 효율적 미세 조정(PEFT) [4, 9, 12, 17]은 학습해야 할 파라미터 수를 전체 미세 조정에 비해 대폭 줄이면서 사전 학습된 모델을 후속 작업으로 전이시키는 것을 목표로 한다. 이러한 감소는 학습 및 저장 비용을 최소화하고, 과적합(overfitting)의 위험을 줄이기 위함이다.

NLP 분야에서는 다양한 PEFT 방법들이 제안되었고, 상당한 성공을 거두었다 [9, 10, 16, 18, 20, 32]. Adapter [8]는 대형 모델을 위한 주요 미세 조정 접근법 중 하나로, 네트워크 구조에 학습 가능한 어댑터 컴포넌트를 삽입하는 병목 구조를 통해 미세 조정을 수행하는 패러다임을 제시한다. 또한, LoRA [9]는 파라미터 수를 줄이기 위해 저차원 분해(low-rank decomposition)를 사용하며, 어댑터를 사이드 패스로 간주하여 미세 조정 중 파라미터 행렬 증가를 시뮬레이션한다. 이후, 사전 학습된 ViT 모델에 맞춘 다양한 PEFT 방법들이 등장했다. VPT [12]는 ViT의 입력 및 중간 레이어에 한정된 수의 학습 가능한 파라미터를 사용하며, 백본을 고정한 상태로 이러한 경량 파라미터만 미세 조정하여 전체 미세 조정보다 뛰어난 성능 향상을 이룬다. SSF [17]는 스케일 및 시프트 작업을 통해 사전 학습된 모델에서 특징을 효율적으로 전이하는 피처 모듈레이션 방법을 도입했다. 연속적인 어댑터 삽입 접근 방식과 달리, AdaptFormer [1]은 ViT의 다양한 후속 작업에 대해 병렬 어댑터 솔루션을 탐구했다. FacT [13]는 텐서 분해 프레임워크를 기반으로 ViT의 파라미터 행렬을 분해 및 재구성하여, 경량 파라미터들이 미세 조정 증가량을 주도하게 하고, 후속 작업을 위한 미세 조정 시 파라미터의 업데이트만 수행함으로써 낮은 미세 조정 비용을 달성했다. ARC [4]는 ViT의 층 간 유사성 관점에서 미세 조정을 접근하며, 파라미터 공유 어댑터 구조와 독립적인 스케일링 요소를 사용하여 다른 방법들보다 적은 미세 조정 비용을 제공한다.

#### 2.3. 제안된 방법에 대한 논의
제안된 방법은 고유한 residual 구조를 통합한다. 저차원 학습 가능한 어댑터만을 도입하는 LoRA [9]와 같은 병렬 구조 방법과 달리, 이로 인해 미세 조정에서의 어려움이 발생할 수 있는데, 우리의 접근법은 모델이 후속 작업에 최적화되면서도 모델의 본래 표현 능력을 유지하는 미세한 균형을 향해 나아가도록 유도한다. SSF [17]와는 대조적으로, 우리는 SVD를 기반으로 한 프레임워크를 통해 singular column vector의 조정을 고려한다는 점에서 차별화된다. 요약하자면, 우리의 연구는 과거 방법론들에 대한 통합된 시각을 제공하며, 이 특정 전략을 위한 설득력 있는 동기를 제시한다.

### 3. 방법론
이 섹션에서는 PEFT 방법과 관련된 기본 개념에 대해 포괄적인 개요를 제공한다. 우리는 SVD를 활용하여 사전 학습된 가중치 행렬을 분석하고, SVD 프레임워크 내에서 인기 있는 PEFT 접근법들의 기저 메커니즘을 심도 있게 탐구한다. 우리의 분석은 사전 학습된 파라미터의 일반화 능력을 유지하는 것과 작업별 적응을 촉진하는 것 사이의 미세한 균형에 초점을 맞춘다. 이러한 분석을 마친 후, 우리는 향상된 미세 조정 성능을 위해 이 trade-off를 최적화하도록 설계된 Residual-based Low-Rank Rescaling (RLRR) 전략을 소개한다.

#### 3.1. PEFT 방법에 대한 기초 지식
ViT는 이미지 분류와 같은 컴퓨터 비전 작업에 Transformer [27] 아키텍처를 적용한 딥 러닝 모델로, 원래는 자연어 처리(NLP)를 위해 설계되었다. ViT 모델은 패치 임베딩 레이어와 Transformer 인코더라는 두 가지 주요 구성 요소로 구성된다. 패치 임베딩 레이어는 입력 이미지 $X \in \mathbb{R}^{H×W×C}$를 고정 크기의 패치 시퀀스로 분할하고, 각 패치를 고차원 벡터로 투영한다. 즉, $X_{patches} \in \mathbb{R}^{N×(P^2 ·C)}$가 된다. 여기서 H와 W는 각각 이미지 해상도의 높이와 너비(H, W)이며, (P, P)는 각 패치의 해상도이고, C는 입력 채널 수, 그리고 $N = H · W/P^2$는 토큰의 수를 나타낸다. 전체 패치 임베딩 레이어는 다음과 같이 설명된다:
$$
X_e = [\vec{x}_{cls}^\top; X_{patches}W_{patches}] + X_{pos},
$$
여기서 학습 가능한 클래스 토큰 $\vec{x}_{cls} \in \mathbb{R}^D$가 선형 투영 $W_{patches} \in \mathbb{R}^{(P^2·C)×D}$을 사용하여 $X_{patches}W_{patches}$에 연결(concatenate)되고, 연결 연산 $[·; ·]$이 수행된다. 또한, 위치 임베딩 $X_{pos} \in \mathbb{R}^{(N+1)×D}$이 포함된다. 그 후 Transformer 인코더는 Multi-Head Attention (MHA) 및 Feed-Forward Network (FFN) 블록을 사용하여 패치 임베딩을 처리한다. MHA 블록에서 Attention Head (AH) 모듈은 다음과 같이 정의된다:
$$
AH_h(X^{(l−1)}) =
\text{softmax}\left(\frac{(X^{(l−1)}W_q^{(l)})(X^{(l−1)}W_k^{(l)})^\top}{\sqrt{D_h^{(l)}}}\right)X^{(l−1)}W_v^{(l)},
$$

다음은 주어진 텍스트의 평어체 한국어 번역입니다:

---

여기서 가중치 행렬 $W_q^{(l)} \in \mathbb{R}^{D^{(l-1)} \times D_h^{(l)}}$, $W_k^{(l)} \in \mathbb{R}^{D^{(l-1)} \times D_h^{(l)}}$, 그리고 $W_v^{(l)} \in \mathbb{R}^{D^{(l-1)} \times D_h^{(l)}}$는 각각 query, key, value 연산에 해당하며, $D_h^{(l)} = \frac{D^{(l)}}{M}$는 출력의 피처 차원이고, $M$은 attention heads의 개수이다. 따라서 전체 MHA 블록은 다음과 같이 정의된다:

$$
MHA(X^{(l-1)}) = [AH_1(X^{(l-1)}), \dots, AH_M(X^{(l-1)})] W_o^{(l)}
$$

여기서 $W_o^{(l)} \in \mathbb{R}^{(M \cdot D_h^{(l)}) \times D^{(l)}}$는 선형 투영 행렬이다. 이후 MHA 블록의 정규화된 출력 $X'^{(l)}$을 FFN 블록에 입력한다:

$$
FFN(X'^{(l)}) = GELU(X'^{(l)} W_1^{(l)}) W_2^{(l)}
$$

여기서 $W_1^{(l)} \in \mathbb{R}^{D^{(l)} \times 4 \cdot D^{(l)}}$와 $W_2^{(l)} \in \mathbb{R}^{4 \cdot D^{(l)} \times D^{(l)}}$는 각각 두 개의 선형 투영 행렬이다. 전체 $l$번째 Transformer 인코더 레이어의 과정은 다음과 같이 정의된다:

$$
X'^{(l)} = MHA(LayerNorm(X^{(l-1)})) + X^{(l-1)}
$$

$$
X^{(l)} = FFN(LayerNorm(X'^{(l)})) + X'^{(l)}
$$

LayerNorm(·) 함수는 레이어 표현 정규화를 수행한다.

ViT와 그 변형 모델을 사용하는 다운스트림 작업에서, 주로 세 가지 유형의 시각적 PEFT(Pre-trained Model Fine-tuning) 방법이 사용된다. 이러한 방법들은 최소한의 새로운 파라미터를 사용하여 사전 학습된 모델을 미세 조정하며, 적응 기반, 프롬프트 기반, 스케일링 및 시프팅 기반 전략으로 나눌 수 있다. 보다 구체적으로, 다음 가중치 행렬을 고려할 때:

$$
W^{(l)} \in \{W_q^{(l)}, W_k^{(l)}, W_v^{(l)}, W_o^{(l)}, W_1^{(l)}, W_2^{(l)}\}
$$

적응 기반 방법의 일반적인 아이디어는 Eq. (7)에서 정의할 수 있으며, 이때 Act(·)는 활성화 함수, $\vec{b}^{(l)}$는 바이어스 가중치, $W_{down} \in \mathbb{R}^{D^{(l)} \times D'}$와 $W_{up} \in \mathbb{R}^{D' \times D^{(l)}}$는 다운샘플링 및 업샘플링 투영 행렬로, 레이어별로 다른 차원 $D^{(l)} \gg D'$을 가진다. 적응 기반 방법의 대표적인 예로는 LoRA(Low-Rank Adaptation)[9]가 있으며, 이는 Eq. (9)로 표현할 수 있다.

두 번째 유형은 프롬프트 기반 방법으로, 이는 Eq. (11)에서 설명되며, 여기서 $\Theta^{(l-1)} \in \mathbb{R}^{T \times D^{(l-1)}}$는 학습 가능한 파라미터로 구성되며 $T$는 가상 토큰이다. 세 번째 유형은 스케일링 및 시프팅 기반 전략으로, 이는 Eq. (13)에서 나타나며, 학습 가능한 스케일링 파라미터 $\vec{s}^{(l)}$, 시프팅 파라미터 $\vec{f}^{(l)}$, 그리고 성분별 Hadamard 곱 $\odot$를 특징으로 한다.

### 3.2. 기존 PEFT 방법을 SVD를 통해 재검토하기

이 섹션에서는 SVD(Singular Value Decomposition)를 사용하여 기존 PEFT 방법의 동작 메커니즘을 재검토한다. 우리의 목표는 사전 학습된 모델의 일반화 능력을 유지하면서 과제 특화 적응을 촉진하는 미세한 균형을 이루는 통합 프레임워크를 확립하는 것이다. 이를 위해 SVD를 사용하여 가중치 행렬 $W^{(l)}$을 다음과 같이 분해한다:

$$
W^{(l)} = \lambda_1^{(l)} \vec{d}_1^{(l)} \vec{u}_1^{(l)^\top} + \dots + \lambda_D^{(l)} \vec{d}_D^{(l)} \vec{u}_D^{(l)^\top}
$$

여기서 스펙트럼(즉, 특이값) $\{\lambda_d^{(l)}\}$, 왼쪽 특이 벡터 $\vec{d}_d^{(l)}$는 왼쪽 유니터리 행렬에서 나오는 벡터이며, 오른쪽 특이 벡터 $\vec{u}_d^{(l)^\top}$는 오른쪽 유니터리 행렬에서 나오는 벡터이다. 이 SVD 프레임워크 아래에서 Eqs. (7), (9), (11), (13)은 Table 1의 Eqs. (8), (10), (12), (14)로 재정의할 수 있다.

이 재정의된 방정식들을 살펴보면, 일반적인 적응 기반 방법들은 스펙트럼에 속한 각 특이 항목 $\lambda_d^{(l)} \vec{d}_d^{(l)} \vec{u}_d^{(l)^\top} W_{down}$을 포함한다. 다운샘플링 투영 행렬 $W_{down}$은 오른쪽 특이 벡터 $\vec{u}_d^{(l)}$에 직접 적용된다. 그러나 이러한 직접적인 적용은 이러한 오른쪽 특이 행렬의 직교성과 같은 공간 구조를 손상시켜 사전 학습된 모델의 표현력을 저하시킬 수 있다. 비슷하게, 프롬프트 기반 방법에서는 학습 가능한 토큰 $\Theta$가 왼쪽 특이 벡터 $\vec{d}_d^{(l)}$와 직접 상호작용하는데, 이로 인해 튜닝이 사전 학습된 모델에서 지나치게 벗어날 수 있다. 스케일링 및 시프팅 기반 방법도 Eq. (14)에서의 성분별 곱셈 $\vec{u}_d^{(l)^\top} \odot \vec{s}^{(l)^\top}$로 인해 동일한 결함을 가진다. 또한, 과도한 적응은 스펙트럼을 방해하여 가중치 용량의 한쪽에 영향을 줄 수 있다. 특히, Eq. (8)에서 $\lambda_d^{(l)} W_{down}$, Eq. (12)에서 $\lambda_d^{(l)} \Theta^{(l-1)}$, 그리고 Eq. (14)에서 $\lambda_d^{(l)} \odot \vec{s}^{(l)^\top}$는 특이 스펙트럼에 미치는 영향을 보여준다. $W_{down}$, $\Theta^{(l-1)}$, 그리고 $\vec{s}^{(l)}$와 같은 파라미터의 잘못된 초기화는 스펙트럼 왜곡과 원래 가중치 용량의 손실을 초래할 수 있다.

반면, Eq. (10)에서 볼 수 있듯이 LoRA 방법의 유일한 저랭크 적응 항목 $W_{down}W_{up}$은 가중치 행렬 $W^{(l)}$의 차원이 클 때 모든 특이 항목 $\{\lambda_d^{(l)} \vec{d}_d^{(l)} \vec{u}_d^{(l)^\top}\}$에 대해 약하게 적응한다. 이러한 약간의 섭동은 가중치 스펙트럼과 특이 벡터를 약간만 변화시켜 사전 학습된 모델의 표현력이 다운스트림 작업에 원활하게 적응할 수 없게 한다.

### 3.3. 잔차 기반 저랭크 리스케일링(RLRR) 방법

다운스트림 작업에서 과적응과 저적응 사이의 균형을 맞추기 위해, 우리는 간단하면서도 효과적인 RLRR 전략을 제안한다. 이는

 Fig. 1에 표시된 바와 같이 이전에 설명한 통합 프레임워크에서 유도될 수 있다:

$$
X_{FT}^{(l-1)} = X^{(l-1)}(W^{(l)} + \Delta W^{(l)}) + \vec{b}^{(l)^\top} + \vec{f}^{(l)^\top}
$$

$$
= X^{(l-1)}(W^{(l)} + \vec{s}_{left}^{(l)} \odot W^{(l)} \odot \vec{s}_{right}^{(l)^\top}) + \vec{b}^{(l)^\top} + \vec{f}^{(l)^\top}
$$

이 식에서, 우리는 가중치 행렬 $W^{(l)}$의 양쪽에 스케일링 파라미터 $\vec{s}_{left}^{(l)}$과 $\vec{s}_{right}^{(l)}$를 추가하여 다운스트림 작업의 특성을 학습할 때 더 유연하게 만든다.

Eq. (16)에서 또한 고정된 가중치 $W^{(l)}$를 $\Delta W^{(l)} = \vec{s}_{left}^{(l)} \odot W^{(l)} \odot \vec{s}_{right}^{(l)^\top}$의 미세 조정 항목에 추가함으로써, RLRR 전략은 과적응과 저적응 사이의 균형을 맞출 수 있다. 구체적으로, Eq. (16)를 다음과 같이 확장할 수 있다:

$$
X_{FT}^{(l-1)} = X^{(l-1)}(\lambda_1^{(l)} \vec{d}_1^{(l)} \vec{u}_1^{(l)^\top} + \dots + \lambda_D^{(l)} \vec{d}_D^{(l)} \vec{u}_D^{(l)^\top}
+ \vec{s}_{left}^{(l)} \odot (\lambda_1^{(l)} \vec{d}_1^{(l)} \vec{u}_1^{(l)^\top} + \dots
+ \lambda_D^{(l)} \vec{d}_D^{(l)} \vec{u}_D^{(l)^\top}) \odot \vec{s}_{right}^{(l)^\top}) + \vec{b}^{(l)^\top} + \vec{f}^{(l)^\top}
$$

이 식에서 우리는 특이 항목을 다음과 같이 얻는다:

$$
W_{item} = \lambda_d^{(l)} \vec{d}_d^{(l)} \vec{u}_d^{(l)^\top} + \lambda_d^{(l)} \vec{s}_{left}^{(l)} \odot \vec{d}_d^{(l)} \vec{u}_d^{(l)^\top} \odot \vec{s}_{right}^{(l)^\top}
$$

각 요소는 다음과 같다:

$$
W_{item}[i,j] = \lambda_d^{(l)} \vec{d}_d^{(l)}[i] \vec{u}_d^{(l)}[j] + \lambda_d^{(l)} \vec{s}_{left}^{(l)}[i] \vec{d}_d^{(l)}[i] \vec{u}_d^{(l)}[j] \vec{s}_{right}^{(l)}[j]
$$

$$
= (1 + \vec{s}_{left}^{(l)}[i] \vec{s}_{right}^{(l)}[j]) \lambda_d^{(l)} \vec{d}_d^{(l)}[i] \vec{u}_d^{(l)}[j]
$$

Eq. (19)에는 사전 학습된 모델의 고유 표현력을 고정시키는 상수 항 1이 있으며, 동시에 미세 조정 항목 $\vec{s}_{left}^{(l)}[i] \vec{s}_{right}^{(l)}[j]$를 활용하여 모델의 용량을 조정하여 다운스트림 작업을 학습할 수 있다.

### Re-parameterization

이전 방법과 유사하게, 우리는 파라미터 행렬에 대한 조정을 선형 연산으로 수행한다. 이를 통해 스케일링 및 시프팅 연산을 원래의 파라미터 행렬에 재파라미터화하여 원활하게 흡수할 수 있다. 다음과 같이 재파라미터화가 가능하다:

$$
W_{re-param}^{(l)} = W^{(l)} + \Delta W^{(l)}
= \left(1 + \vec{s}_{left}^{(l)} \vec{s}_{right}^{(l)^\top} \right) \odot W^{(l)}
$$

$$
\vec{b}_{re-param}^{(l)} = \vec{b}^{(l)} + \vec{f}^{(l)}
$$

여기서 1은 모든 요소가 1인 행렬을 나타내며, 이는 $l$번째 레이어의 원래 파라미터 행렬 $W^{(l)}$와 차원이 일치한다. 벡터 $\vec{s}_{left}^{(l)}$와 $\vec{s}_{right}^{(l)}$는 스케일링 파라미터를, $\vec{f}$ 벡터는 시프팅 파라미터를 나타낸다. Eq. (20)은 스케일링 및 시프팅을 선형 연산을 통해 원래 파라미터 행렬 $W^{(l)}$에 병합할 수 있음을 의미하며, 이는 추론 중에 추가 저장 공간을 필요로 하지 않는다.

### 4. 실험

#### 4.1. 실험 설정

**다운스트림 작업**  
이전 연구들[4, 12, 17]에 따라, 우리는 RLRR을 다섯 가지 세부 시각적 분류(FGVC) 데이터셋과 VTAB1k 벤치마크에서 평가한다. FGVC는 CUB-200-2011[28], NABirds[26], Oxford Flowers[21], Stanford Dogs[14], Stanford Cars[6]로 구성된다. 데이터 분할 방식은 VPT[12]에서 설정한 기준을 따르며 일관성을 유지한다. VTAB1k[31]는 자연, 전문화, 구조화된 세 그룹으로 나뉜 19개의 다양한 시각적 분류 작업을 포함한 벤치마크이다. 자연 그룹은 일상 생활의 이미지를 포함하고, 전문화 그룹은 전문 장비로 촬영한 의학 및 원격 감지 이미지를 포함하며, 구조화된 그룹은 시뮬레이션 환경에서 생성된 합성 이미지를 포함한다. 각 작업은 훈련을 위해 1000장의 이미지만 포함되며, 분류, 객체 수 카운팅, 깊이 추정 등 다양한 다운스트림 작업을 포함한다. 따라서 이는 미세 조정 방법의 효과를 평가하는 포괄적인 측정 도구로 사용된다.

**사전 훈련된 백본**  
우리는 ViT[5]와 Swin Transformer[19]를 백본으로 사용하여 우리의 접근 방식을 평가한다. 또한, RLRR의 다양성을 보여주기 위해 ViT의 세 가지 변형(즉, ViT-Base, ViT-Large, ViT-Huge)을 사용한다. 이 백본 아키텍처들은 모두 ImageNet21K 데이터셋[3]에서 사전 훈련된 파라미터를 활용하며, 기본 설정을 유지한다. 이 설정에는 이미지 패치 수와 은닉층의 피처 차원이 포함된다. 또한, SSF[17]은 AugReg[24]로 확장된 ViT 백본을 사용한다. 공정한 비교를 보장하기 위해, 우리는 이 확장 전략을 사용한 독립 실험을 수행했다(표 2와 표 3 참조).

**기준선 및 기존 PEFT 방법**  
RLRR의 성능을 두 가지 기준선 방법과 여러 잘 알려진 PEFT 접근 방식들, 즉 Adapter[8], Bias[30], LoRA[9], VPT[12], AdaptFormer[1], FacT[13], ARC[4]와 비교하여 평가한다. 두 기준선 방법은 (1) 전체 미세 조정(Full Fine-tuning), 즉 다운스트림 작업의 훈련 데이터를 사용하여 사전 훈련된 모델의 모든 파라미터를 업데이트하는 방법과, (2) 선형 프로빙(Linear Probing), 즉 다운스트림 작업을 위해 선형 분류 헤드만 훈련하고 나머지 사전 훈련된 파라미터는 동결하는 방법이다.

**구현 세부 사항**  
이 작업에서는 VPT[12]에 따라 표준 데이터 증강을 구현한다. 다섯 가지 FGVC 데이터셋의 경우, 랜덤 수평 뒤집기와 랜덤 크롭을 224 × 224 픽셀로 적용한다. VTAB-1k 벤치마크의 경우, 이미지는 224 × 224 픽셀로 크기가 조정되며, 19개의 데이터셋에서 랜덤 수평 뒤집기를 사용한다. 튜닝에 특정한 하이퍼파라미터(예: 학습률, 가중치 감쇠)를 최적화하기 위해 그리드 검색을 수행한다. 모든 실험은 PyTorch 프레임워크[23]를 사용하여 80 GB 메모리의 NVIDIA A800 GPU에서 수행된다.

#### 4.2. 실험 비교

이 섹션에서는 RLRR 방법을 기준선 모델 및 최신 접근 방식들과 비교하는 포괄적인 평가를 진행한다. 두 가지 시각적 적응 벤치마크를 사용하여 각 방법의 분류 정확도를 평가하고, 미세 조정 단계에서의 학습 가능한 파라미터 수를 검토한다. 이러한 평가 결과는 표 2와 표 3에 상세히 나와 있다. 다음과 같은 관찰 결과를 도출할 수 있다:

1. **RLRR 접근 방식**은 기준선 방법들과 기존의 최신 PEFT 방법들에 비해 경쟁력 있는 결과를 나타낸다. 특히, RLRR은 두 가지 시각적 적응 벤치마크에서 대부분의 데이터셋에서 우수한 성능을 기록하며, 대부분의 기존 미세 조정 접근 방식들을 초월한다. 또한, 학습 가능한 파라미터 수를 경쟁력 있게 유지하며, 과도한 계산 비용 없이 높은 효율성을 달성한다. 특히, VTAB-1k 벤치마크에서 RLRR은 19개 데이터셋 중 절반 이상에서 1.1%의 개선(74.5% 대 73.4%)을 달성하며, AugReg로 강화된 모델 대비 0.8%의 향상(75.1% 대 74.3%)을 보여준다. FGVC 데이터셋에서는 두 가지 사전 훈련된 모델 버전을 사용하여 10개 평가 중 7개에서 최적의 성능을 발휘하며, 다양한 다운스트림 작업에서의 일관된 적응력과 강인성을 강조한다. 또한, RLRR과 LoRA는 비슷한 파라미터 수를 가지지만, RLRR이 다운스트림 작업에서 LoRA를 크게 능가한다. 이는 RLRR의 우수한 설계가 사전 훈련된 파라미터 행렬을 잔여 항목의 기초로 활용하여 다운스트림 작업에서 과도한 적응이나 부족한 적응의 잠재적 문제를 방지함을 시사한다. 잔여 항목의 튜닝은 SSF의 고효율 파라미터 조정 설계로 인해 혜택을 본다. 또한, 우리의 접근 방식은 SSF보다 더 큰 유연성을 제공하는 재스케일링 가중치 행렬 설계를 포함하며, VPT와는 달리 복잡한 작업별 학습 가능한 파라미터나 ViT의 부분 모듈 내에서 복잡한 주입 선택이 필요 없어 추가 계산 오버헤드를 피할 수 있다.

2. **PEFT 솔루션과 비교할 때**, 전체 미세 조정(Full fine-tuning)은 유의미한 개선을 나타내지 않는다. 오히려 업데이트된 파라미터 수가 증가함에도 성능이 저하될 수 있다. 이는 대규모 데이터셋에서 얻은 사전 훈련된 모델의 일반화 능력이 손실되어, 다운스트림 작업에서 훈련 데이터에 과적합될 수 있음을 나타낸다. 실제로 전체 미세 조정은 방대한 데이터와 세심한 실험 설정을 필요로 하며, 특히 VTAB-1k 벤치마크에서는 훈련 이미지가 1000장밖에 없어 모델 전체를 미세 조정할 때 종종 과적합의 딜레마에 빠질 수 있다. 이는 경량화된 적응 설계의 효과성과 가능성을 강조한다.

### 대규모 ViT 백본에 대한 실험

**대규모 ViT 백본에서의 실험**  
일반적으로 사용되는 ViT-B/16 백본을 넘어, 우리의 실험은 대규모 백본인 ViT-L/16과 ViT-H/14를 포함하여 RLRR 방법의 확장성과 일반화 능력을 검증한다. 표 4 (a)와 (b)에 명시된 바와 같이, RLRR은 이러한 대규모 백본에 적용하더라도 다른 최신 적응 방법들보다 일관되게 우수한 성능을 발휘한다. 특히, 우리의 방법은 ViT-L/16에서 최신 최신 기법보다 2.7%, ViT-H/14에서는 2.6% 더 우수하다. 이러한 결과는 RLRR이 더 큰 모델로 효과적으로 확장될 수 있는 능력을 보여주며, 다양한 Transformer 기반 아키텍처에서의 효율적인 적응을 위한 강인성을 확인시킨다.

**계층적 Vision Transformer에서의 실험**  
RLRR의 효능을 더욱 입증하기 위해, 우리는 계층적 구조로 구별되는 Transformer 기반 아키텍처인 Swin Transformer[19]에 적용한다. Swin Transformer는 각 단계가 일정한 피처 차원을 가지는 Transformer 블록으로 구성되며, 단계별로 차원이 다르다. 표 5에서 RLRR이 이 전문화된 Transformer 아키텍처에 적응하더라도 경쟁력 있는 적응 정확도를 유지함을 보여준다. 이는 다양한 시각적 적응 작업에 대한 RLRR의 강인성을 확인시킨다.

### 4.3. Ablation Studies

**RLRR 적응 삽입의 효과**  
RLRR 적응의 영향을 평가하기 위해, 우리는 MHA, FFN, LayerNorm을 포함한 다양한 레이어와 Transformer 모듈에 RLRR을 삽입해 실험한다. 특히, LayerNorm의 경우 가중치가 행렬 형태로 저장되지 않기 때문에 SSF[17]와 동일한 접근 방식을 따른다. 구체적인 결과는 그림 2에 나타나 있다. 배치된 레이어 수가 증가함에 따라 모든 설정에서 정확도가 개선되는 것을 관찰한다. 또한, 잔여 항목과 재스케일링 설계를 모든 모듈에 적용한 구성은 다른 구성들보다 일관되게 우수한 성능을 보인다. 따라서, 우리는 잔여 항목과 재스케일링 설계를 모든 모듈에 배치하기로 결정한다.

**다양한 RLRR 조합의 효과**  
잔여 항목과 재스케일링 설계의 중요성을 further 강조하기 위해, 우리는 제안된 방법의 다양한 구성 요소에 대한 ablation 효과를 평가한다. 결과는 표 6에 제시되어 있다. 결과는 잔여 항목이 없는 경우, 단일 측면(즉, 왼쪽 또는 오른쪽) 스케일링 튜닝이 양측(즉, 왼쪽과 오른쪽) 튜닝보다 더 나은 성능을 발휘함을 보여준다. 이는 원래의 사전 훈련된 파라미터 행렬의 과도한 재스케일링이 특히 추가 제약 없이 모델의 일반화 능력을 저하시킬 수 있음을 시사한다. 흥미롭게도, 잔여 항목이 포함될 경우 이 경향이 반전되며, 이는 재스케일링이 유연한 교란을 도입할 수 있음을 보여줄 뿐만 아니라, 잔여 항목이 모델의 본래 표현 능력을 유지하는 데 중요함을 강조한다.

### 5. 결론

이 연구에서는 사전 훈련된 Vision Transformers에 대한 PEFT의 문제를 다루며, 사전 훈련된 모델의 일반화 능력을 유지하면서 다운스트림 작업에 효과적으로 적응하는 미세 조정 전략을 달성하는 데 중점을 두었다. 우리는 PEFT를 새로운 SVD 관점에서 바라보며, 다양한 PEFT 전략의 작동 메커니즘과 그 장단점을 이해할 수 있는 통합 프레임워크를 제시했다.

보다 유리한 트레이드오프를 달성하기 위해, 우리는 RLRR 미세 조정 전략을 도입했다. RLRR은 잔여 항목을 포함하여 적응 유연성을 강화하면서 동시에 사전 훈련된 모델의 표현 능력을 보존한다. 두 개의 다운스트림 벤치마크 데이터셋에서 광범위한 실험을 통해, 우리의 RLRR 방법은 높은 경쟁력 있는 적응 성능을 보였으며 다른 바람직한 특성들도 나타냈다. 이 연구는 PEFT 분야에 대한 귀중한 통찰을 제공하며, 사전 훈련된 Vision Transformers에서 일반화와 작업 특화 적응 간의 미세한 균형을 달성하는 효과적인 전략을 제안한다.