---
slug: P-tuning
title: "GPT Understands, Too"
tags: [PEFT, p-tuning, GPT]
---

논문 및 이미지 출처 : <https://arxiv.org/pdf/2103.10385.pdf>

# Abstract

전통적인 fine-tuning 으로는 GPT model 의 natural language understanding (NLU) task 에 좋은 결과를 달성하지 못하는 반면,

저자는 trainable continuous prompt embeddings 를 사용한 **_P-tuning_** 을 통해 나은 결과를 얻을 수 있었다.

- knowledge probing (LAMA) 벤치마크에서 최고인 GPT 는 테스트할 때 additional text 없이 64% (P@1) 복구 (이전 best 의 +20%)
- SuperGlue 벤치마크에서 GPT 모델은 supervised learning 에서, 유사한 크기인 BERT 와 비슷하거나 더 나은 성능 달성
- P-tuning 이 prompt engineering 의 필요성을 줄여, BERT 모델의 성능도 향상시킨다는 것

결과적으로 P-tuning 이 few-shot SuperGlue 벤치마크에서 SOTA 능가

# 1. Introduction

이전 연구들은 pre-training 과정에 text 표현 뿐 아니라 문법, 구문, 상식 및 세계 지식 등의 요소를 학습한다는 증거를 제시하기도 한다.

training objectives 에 따라 pre-trained language model (LM) 은 세 가지 범주로 나눌 수 있다.

- **unidirectional language models** for natural language generation (NLG) (e.g. GPT)
- **bidirectional language models** for natural language understanding (NLU) (e.g. BERT)
- **hybrid language models** for combining the first two paradigms (e.g. XLNet, UniLM)

GPT 스타일의 모델이 fine-tuning 으로 NLU task 에 대한 성능이 좋지않아, language undetstanding 에 적합하지 않다고 가정해왔다.

하지만 manual prompt 사용으로 흥미로운 성능을 보여, large unidirectional model 와 manual prompt 가 NLU 에 적합하게 작용할 수 있음을 시사

그러나 best-performing prompt 란 사막에서 바늘찾기 이며, 현실적으로 불가능한 매우 큰 검증 데이터셋이 필요하다.

많은 케이스에서도, prompt engineering 은 테스트셋에 overfitting 하며, 큰 성능 하락을 일으키는 prompt 를 만들 가능성도 있다.

이러한 연구들을 통해 저자는 discrete prompts 를 자동으로 검색하고, 효과를 입증하는데 초점을 둔다. 하지만 neural networks 는 continuous 하므로 discrete prompts 는 sub-optimal 일 수 있다.

---

본 연구는 **_P-tuning_** 으로 GPT 와 NLU 간의 간격을 좁히기 위해 continuous space 에서 prompt 를 자동으로 검색하는 방법을 연구

- few continuous free parameters 를 활용하여 pre-trained LM 에 입력으로 제공되는 prompt 역할
- continuous prompt 를 discrete prompt searching 대신 gradient descent 를 활용하여 최적화

간단한 P-tuning 으로 GPT 에 상당한 개선을 가져왔다.

저자는 P-tuning 기반 GPT 을 두 가지 NLU 벤치마크에 검토

- LAMA knowledge probing
  - 64.2% 달성하여 이전 SOPTA prompt searching 방법인 45.2% 를 크게 능가
- SuperGLUE
  - few-shot 및 fine-tuning 을 함께 진행
  - 동일한 규모의 BERT 와 유사한 성능이거나 일부 데이터셋에선 능가
  - BERT 스타일 모델에도 P-tuning 이 이점을 얻을 수 있음을 관찰
  - ALBERT 의 P-tuning 은 성능 크게 능가하고 few-shot SuperGLUE 에서 SOTA

![Figure 1](image-46.png)

위 방법은 GPT 는 언어를 이해하지 못한다는 고정관념을 부쉈다.

P-tuning 은 pre-trained LM 을 downstream task 에 최상의 성능을 위해 fine-tuning 에도 작동한다.

본 논문의 기여는 다음과 같다.

- P-tuning 으로 GPT 의 NLU 가 BERT 와 comparable (때론 더 나음)하여, pre-trained LM 의 성능을 향상 시킴
- P-tuning 은 few-shot 및 fine-tuning 설정에서도 GPT 및 BERT 를 모두 개선
  - LAMA knowledge probing 및 few-shot SuperGLUE 에서 SOTA 능가
  - LM 이 pre-training 중 생각보다 더 많은 지식을 습득했음을 시사

# 2. Motivation

GPT-3 및 DALL-E 는 LLM 이 만병통치약임을 시사하지만, transferability 가 낮다는 것.

downstream task 의 fine-tuning 은 trillion-scale model 에는 거의 작동하지 않는다.

many-shot fine-tuning 에서도 빠르게 fine-tuning sample 을 메모리에 저장하기엔 너무 크다.

대안으로 GPT-3 와 DALL-E 는 downstream 을 위해 model fine-tuning 을 위해 manual prompt 를 활용하는 것이 보고 되었다.

그러나 manual prompt searching 은 큰 검증셋에 지나치게 의존하며 성능도 불안정하다.

![Table 1](image-47.png)

최근 discrete prompts searching 을 자동으로 하는 것에 집중하며, 

- training corpus 를 mining
- gradient searching
- separate model 