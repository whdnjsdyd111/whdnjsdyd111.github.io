---
slug: P-tuning
title: "GPT Understands, Too"
tags: [PEFT, p-tuning, GPT]
---

논문 및 이미지 출처 : <https://arxiv.org/pdf/2103.10385.pdf>

# Abstract

전통적인 fine-tuning 으로는 GPT model 의 natural language understanding (NLU) task 에 좋은 결과를 달성하지 못하는 반면,

저자는 trainable continuous prompt embeddings 를 사용한 **_P-tuning_** 을 통해 나은 결과를 얻을 수 있었다.

- knowledge probing (LAMA) 벤치마크에서 최고인 GPT 는 테스트할 때 additional text 없이 64% (P@1) 복구 (이전 best 의 +20%)
- SuperGlue 벤치마크에서 GPT 모델은 supervised learning 에서, 유사한 크기인 BERT 와 비슷하거나 더 나은 성능 달성
- P-tuning 이 prompt engineering 의 필요성을 줄여, BERT 모델의 성능도 향상시킨다는 것

결과적으로 P-tuning 이 few-shot SuperGlue 벤치마크에서 SOTA 능가

# 1. Introduction

이전 연구들은 pre-training 과정에 text 
언어 모델 사전 학습은 많은 자연어 처리 작업에서 성공적인 접근 방식이었습니다. 이전 연구들은 사전 학습 과정에서 언어 모델이 문맥화된 텍스트 표현뿐만 아니라 문법, 구문, 상식 및 심지어 세계 지식과 같은 요소들을 학습한다는 증거를 제시했습니다.

훈련 목표에 따라 사전 학습된 언어 모델은 세 가지 범주로 나눌 수 있습니다. 일방향 언어 모델 (예: GPT)은 자연어 생성 (NLG)을 위한 것입니다. 양방향 언어 모델 (예: BERT)은 자연어 이해 (NLU)를 위한 것이며, 하이브리드 언어 모델 (예: XLNet, UniLM)은 처음 두 패러다임을 결합하는 것을 목표로 합니다. 오랫동안 연구자들은 GPT 스타일 모델이 파인튜닝을 통해 NLU 작업에 대해 성능이 나쁘다고 관찰했으며, 이러한 이유로 이러한 모델이 본질적으로 언어 이해에 적합하지 않다고 가정해왔습니다.

그러나 GPT-3와 같은 모델은 수동으로 제작된 프롬프트를 사용하여 손으로 제작된 프롬프트를 사용하여 흥미로운 성능을 보였으며, 이러한 성공은 거대한 일방향 언어 모델과 적절한 수동 프롬프트가 자연어 이해에 적합하게 작용할 수 있다는 것을 시사했습니다. 그러나 최상의 성능을 내는 프롬프트를 수동으로 만드는 것은 바늘을 건초더미에서 찾는 것과 같으며, 종종 현실적으로 사용할 수 없는 큰 유효성 검증 데이터 세트가 필요합니다. 많은 경우, 프롬프트 엔지니어링은 테스트 세트에 과적합하는 것을 의미합니다. 또한, 대규모 성능 하락을 일으킬 수 있는 적대적인 프롬프트를 쉽게 만들 수 있습니다.

이러한 문제에 비추어, 최근 연구는 이산 프롬프트를 자동으로 검색하고 이러한 프롬프트의 효과를 입증하는 데 중점을 두었습니다. 그러나 신경망은 본질적으로 연속적이므로 이산 프롬프트는 최적이 아닐 수 있습니다.