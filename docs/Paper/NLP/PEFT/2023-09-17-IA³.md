---
slug: IA³
title: "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"
tags: [PEFT, ICL, few-shot in-context learning, IA³, T-Few]
---

논문 및 이미지 출처 : <https://arxiv.org/pdf/2205.05638.pdf>

# Abstract

Few-shot in-context learning (ICL)은 pre-trained language model (LM) 이 input 의 일부에 적은 수의 training examples 를 feeding 하여 unseen task 를 gradient-based training 없이 수행하게 했다.

- ICL 은 all training examples 를 처리해야 하여 계산, 메모리 및 저장 비용이 큼

Parameter-efficient fine-tuning (PEFT) (e.g. adapter modules, prompt tuning, sparse update, etc) 은 모델이 new task 를 수행하도록 훈련된 parameter small set 을 제공하는 paradigm

---

본 논문은 few-shot ICL 과 PEFT 를 비교하여 PEFT 가 better accuracy 및 lower computational cost 제공을 입증한다.

이 과정에 learned vector 로 activations 를 확장하는 new PEFT 인 $(IA)^3$ 소개

- tiny new parameter 만 도입하여 더 강력한 성능
- T0 model 에 기반하는 _F-Few_ 로, new tasks 에 대한 task-specific tuning 또는 modifications 없이 적용할 수 있는 simple recipe 제안
- T-Few 를 RAFT benchmark 에 적용함으로써 unseen tasks 에 대한 효과성 검증
- super-human 성능을 최초로 6% 로 능가하여 SOTA 달성

# 1. Introduction

