---
slug: RTR
title: "RTR: Prompt Tuning with Rules for Text Classification"
tags: [PEFT, prompt tuning, RTR]
---

논문 및 이미지 출처: <https://www.sciencedirect.com/science/article/pii/S2666651022000183>

# Abstract

최근, pre-trained language models (PLMs) 의 rich knowledge 를 NLP task 에 활성화하기 위해 prompt tuning 이 널리 적용된다.

prompt tuning 이 sentiment classification 및 natural language inference 같은 few-class classification tasks 에 좋은 결과를 보여주지만, prompt 수동 설계는 무거우며 한편, prompts 자동 생성 또한 어렵고 시간 소요가 크다.

그러므로 복잡한 many-class classification 에 대한 효율적인 prompts 를 얻기란 여전히 challenge 로 남아있다.

본 논문에서 저자는 classification task 의 prior knowledge 를 rules 지정하여 encoding 하며, 그 후 rules 에 따라 sub-prompts 를 설계하고, task 를 다루기 위해 sub-prompts 를 결합한다.

저자는 이를 Prompt Tuning method with Rules **"RTR"" 로 명명한다.

존재하는 prompt-based method 와 비교하면, RTR 은 prompts 구축에 효과정 및 효율성 간의 tradeoff 를 잘 도달한다.

relation classification, entity typing 및 intent classification 을 포함한 3개의 many-class classification tasks 에서 실험을 진행한다.

결과는 RTR 이 vanilla 및 prompt tuning baselines 를 능가하는 것을 보여주어, prompt tuning 의 rules 활용의 효과성을 나타냈다.

# 1. Introduction

PLMs 는 효과적인 NLP 수단으로 나타나, large-scale corpora 의 linguistic, semantic, syntactic 및 world knowledge 를 capture 할 수 있다.

task-specific data 를 fine-tuning 하여, PLMs 의 rich knowledge 로 다양한 downstream NLP task 에 활용한다.

fine-tuning 의 성공에도 불구하고, 최근 연구들에서 critical challenge 가 나타난다.

![Figure 1](image.png)

- pre-training 및 fine-tuning 간의 object forms gaps
  - Fig. 1(a) : PLMs