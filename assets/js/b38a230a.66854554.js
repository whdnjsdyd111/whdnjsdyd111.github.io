"use strict";(self.webpackChunkwyj_lab=self.webpackChunkwyj_lab||[]).push([[5938],{94099:e=>{e.exports=JSON.parse('{"label":"vision-language","permalink":"/docs/tags/vision-language","allTagsPath":"/docs/tags","count":8,"items":[{"id":"Paper/Vision-Language/2022-12-Img2LLM","title":"From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Img2LLM"},{"id":"Paper/Vision-Language/Two-Stream/2019-08-LXMERT","title":"LXMERT: Learning Cross-Modality Encoder Representations from Transformers","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Two-Stream/LXMERT"},{"id":"Paper/Vision-Language/2023-03-Prismer","title":"Prismer: A Vision-Language Model with An Esemble of Experts","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Prismer"},{"id":"Paper/Computer Vision/Multi-task/2023-03-UNINEXT","title":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Multi-task/UNINEXT"},{"id":"Paper/Vision-Language/Single-Stream/2019-09-UNITER","title":"UNITER: UNiversal Image-TExt Representation Learning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Single-Stream/UNITER"},{"id":"Paper/Vision-Language/Two-Stream/2019-08-ViLBERT","title":"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Two-Stream/ViLBERT"},{"id":"Paper/Vision-Language/Single-Stream/2019-08-VisualBERT","title":"VisualBERT: A Simple And Performance Baseline For Visual And Language","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98:","permalink":"/docs/Paper/Vision-Language/Single-Stream/VisualBERT"},{"id":"Paper/Vision-Language/Single-Stream/2019-08-VLBERT","title":"VL-BERT: Pre-Training Of Generic Visual-Linguistic Representations","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/Single-Stream/VLBERT"}]}')}}]);