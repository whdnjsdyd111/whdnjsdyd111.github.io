"use strict";(self.webpackChunkwyj_lab=self.webpackChunkwyj_lab||[]).push([[3258],{258:e=>{e.exports=JSON.parse('{"label":"PEFT","permalink":"/docs/tags/peft","allTagsPath":"/docs/tags","count":4,"items":[{"id":"Paper/NLP/PEFT/2023-09-09-LLaMA-Adapter V2","title":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2"},{"id":"Paper/NLP/PEFT/2023-09-08-LLaMA-Adapter","title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/LLaMA-Adapter"},{"id":"Paper/NLP/PEFT/2023-09-06-LoRA","title":"LoRA: Low-Rank Adaptation of Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/LoRA"},{"id":"Paper/NLP/PEFT/2023-08-31-MPT","title":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning"}]}')}}]);