"use strict";(self.webpackChunkwyj_lab=self.webpackChunkwyj_lab||[]).push([[8817],{19176:e=>{e.exports=JSON.parse('{"label":"Adapter","permalink":"/docs/tags/adapter","allTagsPath":"/docs/tags","count":5,"items":[{"id":"Paper/NLP/PEFT/Composition/2023-03-AdaLoRA","title":"Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA"},{"id":"Paper/NLP/PEFT/Soft Prompt/2023-03-LLaMA-Adapter","title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter"},{"id":"Paper/NLP/PEFT/Composition/2021-06-LoRA","title":"LoRA: Low-Rank Adaptation of Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Composition/LoRA"},{"id":"Paper/NLP/PEFT/Module/2019-02-Adapter","title":"Parameter-Efficient Transfer Learning for NLP","description":"\ub17c\ubb38 \uc774\ubbf8\uc9c0 \ubc0f \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Module/Adapter"},{"id":"Paper/NLP/PEFT/Mixture/2022-05-UniPELT","title":"UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Mixture/UniPELT"}]}')}}]);