"use strict";(self.webpackChunkwyj_lab=self.webpackChunkwyj_lab||[]).push([[1580],{79623:e=>{e.exports=JSON.parse('{"label":"Pixel-Level","permalink":"/docs/tags/pixel-level","allTagsPath":"/docs/tags","count":12,"items":[{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2024-03-ADAVIPRO","title":"AdaViPro: Region-Based Adaptive Visual Prompt For Large-Scale Models Adapting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/AdaViPro"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-10-AutoVP","title":"AutoVP: An Automated Visual Prompting Framework and Benchmark","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/AutoVP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-03-DAM-VP","title":"Diversity-Aware Meta Visual Prompting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/DAM-VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-03-EVP-L","title":"Explicit Visual Prompting for Low-Level Structure Segmentations","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/EVP-L"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2024-04-TVP","title":"Exploring the Transferability of Visual Prompting for Multimodal Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/TVP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-03-VP","title":"Exploring Visual Prompts for Adapting Large-Scale Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-11-InMeMo","title":"Instruct Me More! Random Prompting for Visual In-Context Learning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/InMeMo"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-12-LaViP","title":"LaViP: Language-Grounded Visual Prompts","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/LaViP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2024-06-SMM","title":"Sample-specific Masks for Visual Reprogramming-based Prompting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/SMM"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-11-ILM-VP","title":"Understanding and Improving Visual Prompting: A Label-Mapping Perspective","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/ILM-VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-12-EVP","title":"Unleashing the Power of Visual Prompting At the Pixel Level","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/EVP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-10-Watermarking","title":"Watermarking for Out-of-distribution Detection","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/Watermarking"}]}')}}]);