"use strict";(self.webpackChunkwyj_lab=self.webpackChunkwyj_lab||[]).push([[4786],{86747:e=>{e.exports=JSON.parse('{"label":"Visual Prompt","permalink":"/docs/tags/visual-prompt","allTagsPath":"/docs/tags","count":6,"items":[{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-03-DAM-VP","title":"Diversity-Aware Meta Visual Prompting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/DAM-VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2023-03-EVP-L","title":"Explicit Visual Prompting for Low-Level Structure Segmentations","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/EVP-L"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-03-VP","title":"Exploring Visual Prompts for Adapting Large-Scale Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-11-ILM-VP","title":"Understanding and Improving Visual Prompting: A Label-Mapping Perspective","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/ILM-VP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/2022-12-EVP","title":"Unleashing the Power of Visual Prompting At the Pixel Level","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Pixel-Level/EVP"},{"id":"Paper/Vision-Language/PEFT/Visual Prompt/Embedding/2022-11-VPT","title":"Visual Prompt Tuning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Visual Prompt/Embedding/VPT"}]}')}}]);